{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "\n",
    " This section was originally written to play around with the data from a single participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jelkastojanov/anaconda3/bin/python\n",
      "['/Users/jelkastojanov/Documents/GitHub/NMA/garbage', '/Users/jelkastojanov/anaconda3/lib/python37.zip', '/Users/jelkastojanov/anaconda3/lib/python3.7', '/Users/jelkastojanov/anaconda3/lib/python3.7/lib-dynload', '', '/Users/jelkastojanov/anaconda3/lib/python3.7/site-packages', '/Users/jelkastojanov/anaconda3/lib/python3.7/site-packages/aeosa', '/Users/jelkastojanov/anaconda3/lib/python3.7/site-packages/IPython/extensions', '/Users/jelkastojanov/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "print(sys.executable) # This is where this notebook is running in\n",
    "print(sys.path) # This is where the downloaded modules are - sys.executable and sys.path need to be the same to be able to load the module.\n",
    "\n",
    "# Solution:\n",
    "# Run this in Terminal: (output of sys.executable) -m pip install (package name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jelkastojanov/anaconda3/lib/python3.7/site-packages/outdated/utils.py:18: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.3.8, the latest is 0.3.12.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  **kwargs\n",
      "/Users/jelkastojanov/anaconda3/lib/python3.7/site-packages/outdated/utils.py:18: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.0, the latest is 0.2.1.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  **kwargs\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utility'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-097c5f50d13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meinsumfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutility\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utility'"
     ]
    }
   ],
   "source": [
    "# Load packages to convert formats\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import pingouin\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from numpy.core import einsumfunc\n",
    "import utility as ut\n",
    "from nilearn import signal\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File where the NMA fMRI data are\n",
    "path_data = \"/Volumes/DPhil_Jelka/fmri_data/hcp_task\"\n",
    "\n",
    "try: \n",
    "    os.chdir(path_data) \n",
    "except OSError as error: \n",
    "    print(error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jelkastojanov/Documents/GitHub/NMA/garbage'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if you successfully changed directory\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, you want hcp_task to be your specific directory for now\n",
    "HCP_DIR = \"/Volumes/DPhil_Jelka/fmri_data/hcp_task\"\n",
    "if not os.path.isdir(HCP_DIR):\n",
    "    os.mkdir(HCP_DIR)\n",
    "\n",
    "# The data shared for NMA projects is a subset of the full HCP dataset (0-338)\n",
    "N_SUBJECTS = 339\n",
    "\n",
    "# The data have already been aggregated into ROIs from the Glasser parcellation\n",
    "N_PARCELS = 360\n",
    "\n",
    "# The acquisition parameters for all tasks were identical\n",
    "TR = 0.72  # Time resolution, in seconds\n",
    "\n",
    "# The parcels are matched across hemispheres with the same order\n",
    "HEMIS = [\"Right\", \"Left\"]\n",
    "\n",
    "# Each experiment was repeated twice in each subject\n",
    "N_RUNS = 2\n",
    "\n",
    "# There are 7 tasks. Each has a number of 'conditions'\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    'MOTOR'      : {'runs': [5,6],   'cond':['lf','rf','lh','rh','t','cue']},\n",
    "    'WM'         : {'runs': [7,8],   'cond':['0bk_body','0bk_faces','0bk_places','0bk_tools','2bk_body','2bk_faces','2bk_places','2bk_tools']},\n",
    "    'EMOTION'    : {'runs': [9,10],  'cond':['fear','neut']},\n",
    "    'GAMBLING'   : {'runs': [11,12], 'cond':['loss','win']},\n",
    "    'LANGUAGE'   : {'runs': [13,14], 'cond':['math','story']},\n",
    "    'RELATIONAL' : {'runs': [15,16], 'cond':['match','relation']},\n",
    "    'SOCIAL'     : {'runs': [17,18], 'cond':['mental','rnd']}\n",
    "}\n",
    "\n",
    "# You may want to limit the subjects used during code development. This will use all subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load one .npy timeseries file\n",
    "\n",
    "def load_single_timeseries(subject, experiment, run, remove_mean=True):\n",
    "    \"\"\"\n",
    "    Load timeseries data for a single subject and single run.\n",
    "  \n",
    "    Args:\n",
    "    subject (int):      0-based subject ID to load\n",
    "    experiment (str):   Name of experiment \n",
    "    run (int):          0-based run index, across all tasks\n",
    "    remove_mean (bool): If True, subtract the parcel-wise mean (typically the mean BOLD signal is not of interest)\n",
    "\n",
    "    Returns\n",
    "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
    "\n",
    "    \"\"\"\n",
    "    bold_run  = EXPERIMENTS[experiment]['runs'][run]\n",
    "    bold_path = f\"{HCP_DIR}/subjects/{subject}/timeseries\"\n",
    "    bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
    "    ts = np.load(f\"{bold_path}/{bold_file}\")\n",
    "    if remove_mean:\n",
    "        ts -= ts.mean(axis=1, keepdims=True)\n",
    "    return ts\n",
    "\n",
    "\n",
    "def load_evs(subject, experiment, run):\n",
    "    \"\"\"Load EVs (explanatory variables) data for one task experiment.\n",
    "\n",
    "    Args:\n",
    "    subject (int): 0-based subject ID to load\n",
    "    experiment (str) : Name of experiment\n",
    "\n",
    "    Returns\n",
    "    evs (list of lists): A list of frames associated with each condition\n",
    "\n",
    "    \"\"\"\n",
    "    frames_list = []\n",
    "    task_key = 'tfMRI_'+ experiment + '_'+['RL','LR'][run]\n",
    "    for cond in EXPERIMENTS[experiment]['cond']:    \n",
    "        ev_file  = f\"{HCP_DIR}/subjects/{subject}/EVs/{task_key}/{cond}.txt\"\n",
    "        ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
    "        ev       = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
    "    \n",
    "    # Determine when trial starts, rounded down\n",
    "        start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
    "    \n",
    "    # Use trial duration to determine how many frames to include for trial\n",
    "        duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
    "    \n",
    "    # Take the range of frames that correspond to this specific trial\n",
    "        frames = [s + np.arange(0, d) for s, d in zip(start, duration)]\n",
    "        frames_list.append(frames)\n",
    "    \n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_exp  = 'WM'\n",
    "my_subj = 2\n",
    "my_run  = 0\n",
    "\n",
    "data_example = load_single_timeseries(subject = my_subj, experiment = my_exp, run = my_run, remove_mean = True)\n",
    "\n",
    "print(data_example.shape) # 360 ROIs, 405 timepoints\n",
    "print(data_example) # np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about regions\n",
    "regions = np.load(f\"{HCP_DIR}/regions.npy\").T\n",
    "region_info = dict(\n",
    "    name=regions[0].tolist(),\n",
    "    network=regions[1],\n",
    "    hemi=['Right']*int(N_PARCELS/2) + ['Left']*int(N_PARCELS/2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want ROIs in columns\n",
    "regions_T = np.transpose(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many networks are there\n",
    "from collections import Counter\n",
    "\n",
    "# Function to get unique values\n",
    "def unique(list1):\n",
    "   \n",
    "    # Print directly by using * symbol\n",
    "    print(*Counter(list1))\n",
    "\n",
    "unique(regions[1]) #12 networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanatory variables - No clue what they current mean\n",
    "evs = load_evs(subject = my_subj, experiment = my_exp, run = my_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn regions into a pd.dataframe\n",
    "df_regions = pd.DataFrame(regions_T, columns = ['ROI', 'Network', 'Hemi'])\n",
    "print(df_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many regions you have for each network\n",
    "df_regions['Network'].value_counts() # Not even close to an equal number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we want ROIs in columns\n",
    "data_example_T = np.transpose(data_example)\n",
    "data_example_df = pd.DataFrame(data_example_T, columns = [df_regions['ROI'], df_regions['Network']])\n",
    "print(data_example_df.shape) #405 time points, 360 ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform original data_example to a pd.DataFrame\n",
    "data_example_df_original = pd.DataFrame(data_example)\n",
    "print(data_example_df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ROIs and networks\n",
    "Regions_Neural = df_regions.merge(data_example_df_original, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regions_Neural.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_Network = np.arange(0, 360)\n",
    "print(index_Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_Network = Regions_Neural.columns\n",
    "print(columns_Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncorrected full correlations between ROIs\n",
    "ROI_CorrMatrix_Full = data_example_df.corr()\n",
    "print(ROI_CorrMatrix_Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap - Didn't run, matrix is too big\n",
    "sn.heatmap(ROI_CorrMatrix_Full, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncorrected partial correlations between ROIs\n",
    "ROI_CorrMatrix_Partial = data_example_df.pcorr()\n",
    "print(ROI_CorrMatrix_Partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following procedure normalizes the response within ROIs over time\n",
    "scaler = preprocessing.StandardScaler().fit(data_example_df)\n",
    "data_example_df_zscore = scaler.transform(data_example_df)\n",
    "data_example_df_zscore = pd.DataFrame(data_example_df_zscore, columns = data_example_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - Mean\n",
    "np.mean(data_example_df_zscore['R_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - SD\n",
    "np.std(data_example_df_zscore['R_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Data for all participants and tasks (0-back and 2-back) are downloaded, pre-processed and analysed from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add modules folder to Python's search path\n",
    "from os import times\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from os.path import dirname, realpath, abspath\n",
    "script_dir = Path(abspath(''))\n",
    "module_dir = str(script_dir)\n",
    "sys.path.insert(0, module_dir + '/modules')\n",
    "print(module_dir)\n",
    "print(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import task\n",
    "db_path = '{}/data/hcp_task'.format(module_dir)\n",
    "group = task.Group(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 0-back data - X are the features, y are the labels\n",
    "X_0back, y_0back = group.extract_cons(['0bk_faces', '0bk_tools', '0bk_places', '0bk_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(X_0back.shape, y_0back.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2-back data\n",
    "X_2back, y_2back = group.extract_cons(['2bk_faces', '2bk_tools', '2bk_places', '2bk_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_2back.shape, y_2back.shape)\n",
    "\n",
    "# 28080 - 360 (number of ROIs) x 78 (length of the time series)\n",
    "# 1356 - 339 (number of subjects) x 4 (number of conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Ignore the section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate arrays with ROI names and time stamps\n",
    "ROIs = np.array(df_regions['ROI'])\n",
    "ROIs_Full = pd.DataFrame(np.repeat(ROIs, 78), columns = ['ROI'])\n",
    "\n",
    "Timepoints = np.array(range(1,79))\n",
    "Timepoints_Full = pd.DataFrame(np.tile(Timepoints, 360), columns = ['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two and create a combined column\n",
    "ROIs_t = ROIs_Full.merge(Timepoints_Full, left_index=True, right_index=True)\n",
    "ROIs_t['Time'] = ROIs_t['Time'].astype(str)\n",
    "ROIs_t['ROI_t'] = ROIs_t['ROI'].str.cat(ROIs_t['Time'], sep ='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(ROIs_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the features space to pd.DataFrame\n",
    "X_0back_df = pd.DataFrame(X_0back, columns = [ROIs_t['ROI_t']])\n",
    "print(X_0back_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the following column: Participant \n",
    "X_0back_df['Participant'] = np.repeat(np.array(range(0,339)), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the following column: Condition\n",
    "X_0back_df['Condition'] = pd.Series(np.tile(np.array(['faces', 'tools', 'places', 'body']), 339))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(X_0back_df.head())\n",
    "X_0back_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if you can run classifiers in this data structure\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# GLM\n",
    "Classification = LogisticRegressionCV(cv = 8, random_state = 0, multi_class = 'multinomial', max_iter = 10000).fit(X_0back_df.iloc[:, 0:28], X_0back_df.iloc[:, 28081])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "svm.SVC().fit(X_0back_df.iloc[:, 0:28], X_0back_df.iloc[:, 28081])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Functional code for reshaping the dataframe can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = regions[0]\n",
    "subjects = np.arange(339)\n",
    "conditions_0back = ['faces', 'tools', 'places', 'body']\n",
    "conditions_2back = ['faces', 'tools', 'places', 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the dataframe\n",
    "index_0back = []\n",
    "for cond in conditions_0back:\n",
    "    for subj in subjects:\n",
    "        for roi in rois:\n",
    "            index_0back.append((cond, subj, roi))\n",
    "len(index_0back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2back = []\n",
    "for cond in conditions_2back:\n",
    "    for subj in subjects:\n",
    "        for roi in rois:\n",
    "            index_2back.append((cond, subj, roi))\n",
    "len(index_2back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the 0-back task dataframe\n",
    "X_new_0back = X_0back.reshape(488160, 78)\n",
    "\n",
    "index_0back = pd.MultiIndex.from_tuples(index_0back)\n",
    "X_df_0back = pd.DataFrame(X_new_0back, index = index_0back)\n",
    "X_df_0back.index.names = ['Condition', 'Subject_id', 'ROI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(X_df_0back.head())\n",
    "print(X_df_0back.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the 2-back task dataframe\n",
    "X_new_2back = X_2back.reshape(488160, 78)\n",
    "\n",
    "index_2back = pd.MultiIndex.from_tuples(index_2back)\n",
    "X_df_2back = pd.DataFrame(X_new_2back, index = index_2back)\n",
    "X_df_2back.index.names = ['Condition', 'Subject_id', 'ROI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(X_df_2back.head())\n",
    "print(X_df_2back.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to unpack indices (to convert them to columns) - 0-back\n",
    "X_df_0back.reset_index(level=0, inplace=True)\n",
    "X_df_0back.reset_index(level=0, inplace=True)\n",
    "X_df_0back.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to unpack indices (to convert them to columns) - 2-back\n",
    "X_df_2back.reset_index(level=0, inplace=True)\n",
    "X_df_2back.reset_index(level=0, inplace=True)\n",
    "X_df_2back.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the network column\n",
    "df_regions.reset_index(level=0, inplace=True)\n",
    "print(df_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(X_df_0back.head())\n",
    "print(X_df_0back.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the information about the brain network to the data frame\n",
    "X_0back_full = X_df_0back.merge(df_regions, left_on='ROI', right_on='ROI')\n",
    "X_2back_full = X_df_2back.merge(df_regions, left_on='ROI', right_on='ROI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_0back_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_2back_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set indices\n",
    "X_0back_full = X_0back_full.set_index(['Subject_id', 'Condition', 'ROI', 'Network'])\n",
    "X_2back_full = X_2back_full.set_index(['Subject_id', 'Condition', 'ROI', 'Network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary columns\n",
    "del X_0back_full[\"index\"]\n",
    "del X_0back_full[\"Hemi\"]\n",
    "del X_2back_full[\"index\"]\n",
    "del X_2back_full[\"Hemi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2back_0back_contr_ROI = X_2back_full - X_0back_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_2back_0back_contr_ROI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0back_full_grouped = X_0back_full.groupby(['Subject_id', 'ROI'])\n",
    "#scaler = preprocessing.StandardScaler().fit(X_0back_full_grouped.iloc[:, 3:81])\n",
    "nilearn.signal.clean(X_0back_full.iloc[:, 3:81], runs=None, detrend=True, standardize='zscore') \n",
    "#data_example_df_zscore = scaler.transform(data_example_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "\n",
    "Calculate the mean activity on the network level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by condition, network and participant and calculate the mean network activity at each of the 78 time steps\n",
    "X_0back_full_net = X_0back_full.groupby(['Subject_id', 'Condition', 'Network']).mean()\n",
    "X_2back_full_net = X_2back_full.groupby(['Subject_id', 'Condition', 'Network']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 339 (subj) x 4 (cond) x 12 (net) = 16272 rows\n",
    "X_0back_full_net.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_0back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return indices to columns (0-back)\n",
    "X_0back_full_net.reset_index(level=0, inplace=True)\n",
    "X_0back_full_net.reset_index(level=0, inplace=True)\n",
    "X_0back_full_net.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return indices to columns (2-back)\n",
    "X_2back_full_net.reset_index(level=0, inplace=True)\n",
    "X_2back_full_net.reset_index(level=0, inplace=True)\n",
    "X_2back_full_net.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_0back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_2back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the column you don't need\n",
    "del X_0back_full_net[\"index\"]\n",
    "del X_2back_full_net[\"index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Ignore the code below - DO NOT rename the columns as that will throw an error when you try to subtract the 2-back and 0-back dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename time point columns\n",
    "cols_0back = X_0back_full_net.columns\n",
    "cols_2back = X_2back_full_net.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_0back = np.asarray(cols_0back, dtype=str)\n",
    "cols_2back = np.asarray(cols_2back, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_0back = np.core.defchararray.add(cols_0back, '_0_back')\n",
    "cols_2back = np.core.defchararray.add(cols_2back, '_2_back')\n",
    "\n",
    "cols_0back[0] = 'Network'\n",
    "cols_0back[1] = 'Condition'\n",
    "cols_0back[2] = 'Subject_id'\n",
    "\n",
    "cols_2back[0] = 'Network'\n",
    "cols_2back[1] = 'Condition'\n",
    "cols_2back[2] = 'Subject_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(cols_0back)\n",
    "print(cols_2back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names\n",
    "X_0back_full_net.columns = cols_0back\n",
    "X_2back_full_net.columns = cols_2back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_0back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_2back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 0-back and 2-back tasks\n",
    "X_0back_2back = X_0back_full_net.merge(X_2back_full_net, left_on=['Network', 'Condition', 'Subject_id'], right_on=['Network', 'Condition', 'Subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_0back_2back.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Create a contrast dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast 2-back - 0-back\n",
    "X_0back_full_net = X_0back_full_net.set_index(['Network', 'Condition', 'Subject_id'])\n",
    "X_2back_full_net = X_2back_full_net.set_index(['Network', 'Condition', 'Subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_0back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_2back_full_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contrast dataframe\n",
    "X_2back_0back_contr = X_2back_full_net - X_0back_full_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2back_0back_contr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return indices to columns (2-back)\n",
    "X_2back_0back_contr.reset_index(level=0, inplace=True)\n",
    "X_2back_0back_contr.reset_index(level=0, inplace=True)\n",
    "X_2back_0back_contr.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2back_0back_contr_ROI.reset_index(level=0, inplace=True)\n",
    "X_2back_0back_contr_ROI.reset_index(level=0, inplace=True)\n",
    "X_2back_0back_contr_ROI.reset_index(level=0, inplace=True)\n",
    "X_2back_0back_contr_ROI.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the networks - Original ROI activity\n",
    "Visual1 = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Visual1']\n",
    "Visual2 = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Visual2']\n",
    "Somatomotor = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Somatomotor']\n",
    "Cingulo_Oper = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Cingulo-Oper']\n",
    "Language = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Language']\n",
    "Default = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Default']\n",
    "Frontopariet = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Frontopariet']\n",
    "Auditory = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Auditory']\n",
    "Dorsal_atten = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Dorsal-atten']\n",
    "Posterior_Mu = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Posterior-Mu']\n",
    "Orbito_Affec = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Orbito-Affec']\n",
    "Ventral_Mult = X_2back_0back_contr_ROI.loc[X_2back_0back_contr_ROI['Network'] == 'Ventral-Mult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the networks - Mean activity\n",
    "Visual1_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Visual1']\n",
    "Visual2_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Visual2']\n",
    "Somatomotor_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Somatomotor']\n",
    "Cingulo_Oper_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Cingulo-Oper']\n",
    "Language_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Language']\n",
    "Default_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Default']\n",
    "Frontopariet_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Frontopariet']\n",
    "Auditory_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Auditory']\n",
    "Dorsal_atten_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Dorsal-atten']\n",
    "Posterior_Mu_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Posterior-Mu']\n",
    "Orbito_Affec_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Orbito-Affec']\n",
    "Ventral_Mult_mean = X_2back_0back_contr.loc[X_2back_0back_contr['Network'] == 'Ventral-Mult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visual2.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visual2_mean.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEXT STEPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# NORMALIZING DATA - It is very important to figure out what is meant by this and how to execute it.\n",
    "# NORMALIZING DATA - This might probably need to be done before creating contrasts or anything.\n",
    "# WITHIN-NETWORK CLASSIFICATION - Doing the classification within each network + Regularization?\n",
    "# CROSS-VALIDATION - Are we 'manually' splitting the data into train/test or is the function doing that for us?\n",
    "# REGULARIZATION - L2 applied everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Fitting the GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - Same for all networks\n",
    "# Dimensionality:\n",
    "# 1) ROI-level\n",
    "# 2) Average network activity\n",
    "model = LogisticRegression(multi_class = 'multinomial', max_iter = 10000, solver='lbfgs', penalty='l2', C=1)\n",
    "\n",
    "# Define the model evaluation procedure - Same for all networks\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "\n",
    "Network-by-network analysis (with ROI-level activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Visual 1\n",
    "n_scores_V1_ROI = cross_val_score(model, Visual1.iloc[:, 4:82], Visual1.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.480, SD = 0.018)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_V1_ROI), np.std(n_scores_V1_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Visual 2\n",
    "n_scores_V2_ROI = cross_val_score(model, Visual2.iloc[:, 4:82], Visual2.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.526, SD = 0.005)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_V2_ROI), np.std(n_scores_V2_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Somatomotor\n",
    "n_scores_SM_ROI = cross_val_score(model, Somatomotor.iloc[:, 4:82], Somatomotor.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.404, SD = 0.007)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_SM_ROI), np.std(n_scores_SM_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Cingulo-Oper\n",
    "n_scores_CO_ROI = cross_val_score(model, Cingulo_Oper.iloc[:, 4:82], Cingulo_Oper.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.412, SD = 0.005)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_CO_ROI), np.std(n_scores_CO_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Language\n",
    "n_scores_LA_ROI = cross_val_score(model, Language.iloc[:, 4:82], Language.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.51, SD = 0.008)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_LA_ROI), np.std(n_scores_LA_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Default\n",
    "n_scores_DE_ROI = cross_val_score(model, Default.iloc[:, 4:82], Default.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.424, SD = 0.009)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_DE_ROI), np.std(n_scores_DE_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Frontopariet\n",
    "n_scores_FP_ROI = cross_val_score(model, Frontopariet.iloc[:, 4:82], Frontopariet.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.468, SD = 0.008)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_FP_ROI), np.std(n_scores_FP_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Auditory\n",
    "n_scores_AU_ROI = cross_val_score(model, Auditory.iloc[:, 4:82], Auditory.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.459, SD = 0.010)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_AU_ROI), np.std(n_scores_AU_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Dorsal-atten\n",
    "n_scores_DA_ROI = cross_val_score(model, Dorsal_atten.iloc[:, 4:82], Dorsal_atten.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.414, SD = 0.016)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_DA_ROI), np.std(n_scores_DA_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Posterior-Mu\n",
    "n_scores_PM_ROI = cross_val_score(model, Posterior_Mu.iloc[:, 4:82], Posterior_Mu.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.397, SD = 0.004)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_PM_ROI), np.std(n_scores_PM_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Orbito-Affec\n",
    "n_scores_OA_ROI = cross_val_score(model, Orbito_Affec.iloc[:, 4:82], Orbito_Affec.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.329, SD = 0.016)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_OA_ROI), np.std(n_scores_OA_ROI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Ventral-Mult\n",
    "n_scores_VM_ROI = cross_val_score(model, Ventral_Mult.iloc[:, 4:82], Ventral_Mult.iloc[:, 2], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.423, SD = 0.018)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_VM_ROI), np.std(n_scores_VM_ROI)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "\n",
    "Network-by-network analysis (with mean network-level activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Visual 1\n",
    "n_scores_V1 = cross_val_score(model, Visual1_mean.iloc[:, 3:81], Visual1_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.51, SD = 0.034)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_V1), np.std(n_scores_V1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FOCUS ON VISUAL 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.653 (0.040)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and collect the scores - Visual 2\n",
    "n_scores_V2 = cross_val_score(model, Visual2_mean.iloc[:, 3:81], Visual2_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.653, SD = 0.040)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_V2), np.std(n_scores_V2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 2\n",
    "model.fit(Visual2_mean.iloc[:, 3:81], Visual2_mean.iloc[:, 1])\n",
    "model.coef_.shape #(4,78) - 4 classes, 78 features\n",
    "model.intercept_.shape #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 2\n",
    "# Split into the training and testing set\n",
    "X_train,X_test,y_train,y_test=train_test_split(Visual2_mean.iloc[:, 3:81], Visual2_mean.iloc[:, 1], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model \n",
    "logreg = LogisticRegression(multi_class = 'multinomial', max_iter = 10000, solver='lbfgs', penalty='l2', C=1)\n",
    "\n",
    "# Fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "# Predict \n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445624822693215"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "\n",
    "y_test_lb = lb.transform(y_test)\n",
    "y_pred_lb = lb.transform(y_pred)\n",
    "\n",
    "roc_auc_score(y_test_lb, y_pred_lb, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected Output</th>\n",
       "      <th>Predicted Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10067</th>\n",
       "      <td>places</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>body</td>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>faces</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>faces</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>tools</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6983</th>\n",
       "      <td>faces</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>faces</td>\n",
       "      <td>faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>faces</td>\n",
       "      <td>faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>faces</td>\n",
       "      <td>faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15587</th>\n",
       "      <td>places</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>places</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12743</th>\n",
       "      <td>faces</td>\n",
       "      <td>faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>faces</td>\n",
       "      <td>faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>faces</td>\n",
       "      <td>faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>places</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>places</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>places</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>tools</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>places</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14435</th>\n",
       "      <td>places</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Expected Output Predicted Output\n",
       "10067          places           places\n",
       "7595             body             body\n",
       "11975           faces           places\n",
       "10967           faces            tools\n",
       "9551            tools            tools\n",
       "6983            faces            tools\n",
       "7991            faces            faces\n",
       "2903            faces            faces\n",
       "6695            faces            faces\n",
       "15587          places           places\n",
       "11123          places           places\n",
       "12743           faces            faces\n",
       "6071            faces            faces\n",
       "6839            faces            faces\n",
       "11171          places           places\n",
       "12851          places            tools\n",
       "3875           places           places\n",
       "3599            tools            tools\n",
       "5267           places           places\n",
       "14435          places           places"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visually compare output\n",
    "output = pd.DataFrame()\n",
    "output['Expected Output'] = y_test\n",
    "output['Predicted Output'] = y_pred\n",
    "output.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names=['Faces', 'Tools', 'Places', 'Body parts'] # Name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "{'body': 0.7624551888960382, 'tools': 0.6646921780509567, 'faces': 0.7390756302521009, 'places': 0.8120269318781905}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "  # Creating a set of all the unique classes using the actual class list\n",
    "  unique_class = set(actual_class)\n",
    "  roc_auc_dict = {}\n",
    "  for per_class in unique_class:\n",
    "    # Creating a list of all the classes except the current class \n",
    "    other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "    # Narking the current class as 1 and all other classes as 0\n",
    "    new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "    new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "    # Using the sklearn metrics method to calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "    roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "  return roc_auc_dict\n",
    "\n",
    "print(\"\\nLogistic Regression\")\n",
    "\n",
    "# Assuming your already have a list of actual_class and predicted_class from the logistic regression classifier\n",
    "lr_roc_auc_multiclass = roc_auc_score_multiclass(y_test, y_pred)\n",
    "print(lr_roc_auc_multiclass) #0.25 would be worthless classifier, 1 is perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred_train))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Somatomotor\n",
    "n_scores_SM = cross_val_score(model, Somatomotor_mean.iloc[:, 3:81], Somatomotor_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Eeport the model performance (M = 0.44, SD = 0.041)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_SM), np.std(n_scores_SM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Cingulo-Oper\n",
    "n_scores_CO = cross_val_score(model, Cingulo_Oper_mean.iloc[:, 3:81], Cingulo_Oper_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.47, SD = 0.039)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_CO), np.std(n_scores_CO)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Language\n",
    "n_scores_LA = cross_val_score(model, Language_mean.iloc[:, 3:81], Language_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.61, SD = 0.043)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_LA), np.std(n_scores_LA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Default\n",
    "n_scores_DE = cross_val_score(model, Default_mean.iloc[:, 3:81], Default_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.49, SD = 0.039)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_DE), np.std(n_scores_DE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Frontopariet\n",
    "n_scores_FP = cross_val_score(model, Frontopariet_mean.iloc[:, 3:81], Frontopariet_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.56, SD = 0.033)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_FP), np.std(n_scores_FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Auditory\n",
    "n_scores_AU = cross_val_score(model, Auditory_mean.iloc[:, 3:81], Auditory_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Eeport the model performance (M = 0.50, SD = 0.036)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_AU), np.std(n_scores_AU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Dorsal-atten\n",
    "n_scores_DA = cross_val_score(model, Dorsal_atten_mean.iloc[:, 3:81], Dorsal_atten_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.45, SD = 0.038)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_DA), np.std(n_scores_DA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Posterior-Mu\n",
    "n_scores_PM = cross_val_score(model, Posterior_Mu_mean.iloc[:, 3:81], Posterior_Mu_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.46, SD = 0.041)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_PM), np.std(n_scores_PM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Orbito-Affec\n",
    "n_scores_OA = cross_val_score(model, Orbito_Affec_mean.iloc[:, 3:81], Orbito_Affec_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.37, SD = 0.035)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_OA), np.std(n_scores_OA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and collect the scores - Ventral-Mult\n",
    "n_scores_VM = cross_val_score(model, Ventral_Mult_mean.iloc[:, 3:81], Ventral_Mult_mean.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance (M = 0.49, SD = 0.044)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_VM), np.std(n_scores_VM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "\n",
    "Trying out the 2-back task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return indices to columns (2-back)\n",
    "X_2back_full_net.reset_index(level=0, inplace=True)\n",
    "X_2back_full_net.reset_index(level=0, inplace=True)\n",
    "X_2back_full_net.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 2 - 2-back\n",
    "Visual2_2back = X_2back_full_net.loc[X_2back_full_net['Network'] == 'Visual2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "unique(Visual2_2back['Network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-back task\n",
    "\n",
    "# Evaluate the model and collect the scores - Visual 2\n",
    "n_scores_V2_2back = cross_val_score(model, Visual2_2back.iloc[:, 3:81], Visual2_2back.iloc[:, 1], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report the model performance \n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores_V2_2back), np.std(n_scores_V2_2back)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the entire accuracy array\n",
    "print(n_scores_V2_2back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Normalization - Jelka\n",
    "\n",
    "Fourier transform - Alaleh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data to deal with it in R\n",
    "X_2back_full.to_csv(\"/Users/jelkastojanov/Downloads/Two_back_task_NMA.csv\")\n",
    "X_0back_full.to_csv(\"/Users/jelkastojanov/Downloads/Zero_back_task_NMA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File WM_0back_z does not exist: 'WM_0back_z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-11b0384cd449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import the z-transformed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WM_0back_z\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WM_2back_z\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File WM_0back_z does not exist: 'WM_0back_z'"
     ]
    }
   ],
   "source": [
    "# Import the z-transformed data\n",
    "pd.read_csv(\"/Users/jelkastojanov/Documents/GitHub/NMA/garbage/WM_0back_z\")\n",
    "pd.read_csv(\"/Users/jelkastojanov/Documents/GitHub/NMA/garbage/WM_2back_z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
